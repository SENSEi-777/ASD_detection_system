{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ef9f7e-bec6-465b-b44c-70aca9693370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (1.43.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (2.2.1)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (4.11.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.7)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit scikit-learn seaborn joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2cb793-f824-451a-bb5b-ebbfb2734a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: Index(['id', 'A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score',\n",
      "       'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age',\n",
      "       'gender', 'ethnicity', 'jundice', 'austim', 'contry_of_res',\n",
      "       'used_app_before', 'result', 'age_desc', 'relation', 'Class/ASD'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Autism-Child-Data.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print column names\n",
    "print(\"Columns in dataset:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3affae4d-a821-4118-b87e-026f10d99c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically detect the last column as target\n",
    "target_column = df.columns[-1]\n",
    "\n",
    "# Convert categorical target values into numerical values (0 or 1)\n",
    "df[target_column] = df[target_column].map({'YES': 1, 'NO': 0})  # Adjust mapping as needed\n",
    "\n",
    "# Handle missing values in the target column by assignment instead of inplace\n",
    "df[target_column] = df[target_column].fillna(0)\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f22c742-930d-4586-9d1b-0a82b4f91088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ---------------------------\n",
    "# Predefined Q&A Dictionary\n",
    "# ---------------------------\n",
    "sample_qa = {\n",
    "    \"What is ASD?\": (\n",
    "        \"ASD (Autism Spectrum Disorder) is a developmental disorder affecting social communication and behavior.\"\n",
    "    ),\n",
    "    \"What are symptoms?\": (\n",
    "        \"Common ASD symptoms include difficulty with social interactions, repetitive behaviors, and challenges in communication.\"\n",
    "    ),\n",
    "    \"How is it diagnosed?\": (\n",
    "        \"ASD is diagnosed through behavioral assessments, standardized screening tools, and clinical evaluations.\"\n",
    "    ),\n",
    "    \"What is the treatment?\": (\n",
    "        \"Treatment for ASD often includes behavioral therapy, speech therapy, occupational therapy, and educational support.\"\n",
    "    ),\n",
    "    \"Can it be cured?\": (\n",
    "        \"There is no cure for ASD, but early intervention and therapies can help manage symptoms.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# Helper Functions\n",
    "# ---------------------------\n",
    "def chatbot_response(user_input):\n",
    "    \"\"\"\n",
    "    Return a keyword-based response for ASD-related questions.\n",
    "    \"\"\"\n",
    "    text = user_input.lower()\n",
    "    if \"asd\" in text:\n",
    "        return \"ASD (Autism Spectrum Disorder) is a developmental disorder affecting social communication and behavior.\"\n",
    "    elif \"symptom\" in text:\n",
    "        return \"Common ASD symptoms include difficulty with social interactions, repetitive behaviors, and challenges in communication.\"\n",
    "    elif \"diagnos\" in text:\n",
    "        return \"ASD is diagnosed through behavioral assessments, standardized screening tools, and clinical evaluations.\"\n",
    "    elif \"cure\" in text:\n",
    "        return \"There is no cure for ASD, but therapies and support can help manage symptoms.\"\n",
    "    elif \"treat\" in text:\n",
    "        return \"Treatment for ASD often includes behavioral therapy, speech therapy, occupational therapy, and educational support.\"\n",
    "    else:\n",
    "        return \"Sorry, I don't understand that question. Try asking about ASD symptoms, diagnosis, or treatment.\"\n",
    "\n",
    "def preprocess_data(df, target_column):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset:\n",
    "      1) Drop irrelevant columns if needed (e.g., 'Age_Mons', 'id', 'result').\n",
    "      2) Convert the target column from 'YES'/'NO' to 1/0 if it's object-type.\n",
    "      3) Label encode object columns (except target) and store encoders.\n",
    "    \"\"\"\n",
    "    # Drop columns that may leak information\n",
    "    for col in ['Age_Mons', 'id', 'result']:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    # Convert target column from YES/NO to 1/0 if needed\n",
    "    if df[target_column].dtype == 'object':\n",
    "        df[target_column] = df[target_column].map({'YES': 1, 'NO': 0})\n",
    "        df[target_column] = df[target_column].fillna(0)\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and col != target_column:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            label_encoders[col] = le\n",
    "    return df, label_encoders\n",
    "\n",
    "# ---------------------------\n",
    "# Streamlit App\n",
    "# ---------------------------\n",
    "st.title(\"Autism Spectrum Disorder (ASD) Detection for Children\")\n",
    "\n",
    "# Upload CSV file\n",
    "uploaded_file = st.file_uploader(\"Upload your Autism-Child-Data.csv file\", type=[\"csv\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "    st.subheader(\"Dataset Preview\")\n",
    "    st.write(df.head())\n",
    "    \n",
    "    # Set target column (assumed to be \"Class/ASD\")\n",
    "    target_column = \"Class/ASD\"\n",
    "    st.write(f\"Detected Target Column: **{target_column}**\")\n",
    "    \n",
    "    # Preprocess Data (remove leaking columns and label encode)\n",
    "    df_processed, encoders = preprocess_data(df.copy(), target_column)\n",
    "    \n",
    "    # Separate features (X) and target (y)\n",
    "    X = df_processed.drop(columns=[target_column])\n",
    "    y = df_processed[target_column].astype(int)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Model Handling: Load or Train Model\n",
    "    # ---------------------------\n",
    "    model_file = \"asd_model_children.pkl\"\n",
    "    retrain_flag = False\n",
    "    try:\n",
    "        model = joblib.load(model_file)\n",
    "        # Check if model's training features include any leaking columns\n",
    "        if hasattr(model, \"feature_names_in_\") and any(leak in model.feature_names_in_ for leak in [\"id\", \"result\"]):\n",
    "            st.warning(\"Pre-trained model contains leaking columns. Retraining to remove them.\")\n",
    "            retrain_flag = True\n",
    "    except FileNotFoundError:\n",
    "        retrain_flag = True\n",
    "    \n",
    "    if retrain_flag:\n",
    "        st.write(\"ðŸ›  Training new model without leaking columns...\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, model_file)\n",
    "        st.write(\"âœ… Model trained and saved.\")\n",
    "    else:\n",
    "        st.write(\"âœ… Pre-trained model loaded.\")\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Model Evaluation\n",
    "    # ---------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    st.subheader(f\"Model Accuracy on Test Split: {accuracy:.2%}\")\n",
    "    \n",
    "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    st.write(\"Cross-Validation Scores:\", cv_scores)\n",
    "    st.write(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    st.write(\"Confusion Matrix:\")\n",
    "    st.write(cm)\n",
    "    st.text(\"Classification Report:\\n\" + classification_report(y_test, preds))\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Prediction Section\n",
    "    # ---------------------------\n",
    "    st.subheader(\"Make a Prediction\")\n",
    "    user_input = {}\n",
    "    \n",
    "    # For each feature in X, create input fields\n",
    "    for col in X.columns:\n",
    "        if col in encoders:\n",
    "            # For categorical features, use selectbox with original labels\n",
    "            original_categories = list(encoders[col].classes_)\n",
    "            user_input[col] = st.selectbox(f\"Select {col}\", original_categories)\n",
    "        else:\n",
    "            # For numeric features, use number input\n",
    "            min_val = float(X[col].min())\n",
    "            max_val = float(X[col].max())\n",
    "            median_val = float(X[col].median())\n",
    "            user_input[col] = st.number_input(f\"Enter value for {col}\", min_val, max_val, median_val)\n",
    "    \n",
    "    if st.button(\"Predict\"):\n",
    "        # Debug: Display current user input\n",
    "        st.write(\"Current user inputs:\", user_input)\n",
    "        input_df = pd.DataFrame([user_input])\n",
    "        # Safely transform categorical columns\n",
    "        for col, le in encoders.items():\n",
    "            if col in input_df.columns:\n",
    "                user_value = input_df[col].iloc[0]\n",
    "                valid_classes = set(le.classes_)\n",
    "                if user_value not in valid_classes:\n",
    "                    st.error(f\"Unseen category '{user_value}' for column '{col}'. Please pick a valid option.\")\n",
    "                    st.stop()\n",
    "                else:\n",
    "                    input_df[col] = le.transform(input_df[col])\n",
    "        \n",
    "        prediction = model.predict(input_df)[0]\n",
    "        result_text = \"ASD Positive\" if prediction == 1 else \"ASD Negative\"\n",
    "        st.success(f\"Prediction: **{result_text}**\")\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Data Visualization Section\n",
    "    # ---------------------------\n",
    "    st.subheader(\"Data Analysis\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.countplot(x=df[target_column], ax=ax)\n",
    "    ax.set_title(\"Distribution of ASD Classification\")\n",
    "    st.pyplot(fig)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Chatbot Section\n",
    "    # ---------------------------\n",
    "    st.subheader(\"Chatbot - Ask about ASD\")\n",
    "    st.write(\"Select a common question to get an answer:\")\n",
    "    \n",
    "    question_options = list(sample_qa.keys())\n",
    "    selected_question = st.selectbox(\"Common Questions\", question_options)\n",
    "    \n",
    "    if st.button(\"Get Answer\"):\n",
    "        answer = sample_qa[selected_question]\n",
    "        st.write(answer)\n",
    "    \n",
    "    st.markdown(\"**Disclaimer:** This tool is for educational purposes only and should not replace professional medical advice.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312c5fcb-7e8e-4d35-b0ae-cd7a9e14740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2429eca-cf7a-46b3-8cbe-704aad44d83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f99dc64-6954-4edf-9602-603ead646200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae21430-176e-41ef-9013-dad800fc3d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.anaconda', '.bito', '.cache', '.conda', '.condarc', '.continuum', '.ipynb_checkpoints', '.ipython', '.jupyter', '.matplotlib', '.mozilla', '.ms-ad', '.nbi', '.oracle_jre_usage', '.profile', '.redhat', '.vivado_hls', '.vscode', '.Xilinx', '1styrresult.pdf', 'ai', 'AICTE Internship profile.pdf', 'anaconda3', 'app.py', 'AppData', 'Application Data', 'archive (3).zip', 'archive (4).zip', 'archive.zip', 'ASD_Project.ipynb', 'Autism-Child-Data.csv', 'Automobile.csv', 'c-prog', 'clg', 'Cloud_Fundamental.pptx[1].pdf', 'Contacts', 'Cookies', 'Documents', 'Downloads', 'Favorites', 'ibm', 'IMG_20241221_192029.jpg', 'IMG_5454.jpeg.jpg', 'IMG_5471.png', 'IMG_5578.jpeg.jpg', 'inAsc.txt', 'inDesc.txt', 'indian_summer_beauty_products.csv', 'inRand.txt', 'IntelGraphicsProfiles', 'Introduction_to_Cloud.pptx[1].pdf', 'KIIT HDFC Payment gateway.pdf', 'LAB1_3629.ipynb', 'LAB2_3629.ipynb', 'LAB3Dictinaryy.ipynb', 'LAB3Dictionary_3629.ipynb', 'LAB5.ipynb', 'LINEAR_REG.ipynb', 'Links', 'Local Settings', 'Matplotlib.ipynb', 'MATPLOTLIB.py', 'matplotlib_LAB5.ipynb', 'MinGW Installer.lnk', 'ML', 'movies.csv', 'Music', 'My Documents', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{2ad838bb-efea-11ee-a54d-000d3a94eaa1}.TxR.0.regtrans-ms', 'NTUSER.DAT{2ad838bb-efea-11ee-a54d-000d3a94eaa1}.TxR.1.regtrans-ms', 'NTUSER.DAT{2ad838bb-efea-11ee-a54d-000d3a94eaa1}.TxR.2.regtrans-ms', 'NTUSER.DAT{2ad838bb-efea-11ee-a54d-000d3a94eaa1}.TxR.blf', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TM.blf', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'Numpy.ipynb', 'OneDrive', 'Oracle', 'outMergeAsce.txt', 'outMergeDesc.txt', 'outMergeRand.txt', 'output.csv', 'PANDAS.ipynb', 'PrintHood', 'Projection of Solid.dwg', 'QEM_intro.pdf', 'Recent', 'Registration for Forma.ai Internship Cum PPO Recruitment Drive - 2026 Graduating Batch.pdf', 'Registration for JP Morgan Chase (SEP) â€“ Full Time for 2026 Graduating Batch.pdf', 'Remittance Form KIIT FEST 8.0 TIMELESS KANVAS.docx', 'Salaries.csv', 'Saved Games', 'Searches', 'second.c', 'sem1', 'SendTo', 'shrey.am', 'Start Menu', 'student_data.csv', 'Templates', 'TIMELESS KANVAS_RF.docx', 'uhv', 'UNIT_-_1a.pptx[1].pdf', 'UNIT_-_1b.pptx[1].pdf', 'Untitled.ipynb', 'Untitled1.ipynb', 'Videos', 'Virtualization.pptx[1].pdf', 'VM_Provisioning.pptx[1].pdf', 'WPS Cloud Files']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2ef32a5-ffeb-4a35-90ea-f8342bac34b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known positive row found:\n",
      " id                             5\n",
      "A1_Score                       1\n",
      "A2_Score                       1\n",
      "A3_Score                       1\n",
      "A4_Score                       1\n",
      "A5_Score                       1\n",
      "A6_Score                       1\n",
      "A7_Score                       1\n",
      "A8_Score                       1\n",
      "A9_Score                       1\n",
      "A10_Score                      1\n",
      "age                            5\n",
      "gender                         m\n",
      "ethnicity                 Others\n",
      "jundice                      yes\n",
      "austim                        no\n",
      "contry_of_res      United States\n",
      "used_app_before               no\n",
      "result                        10\n",
      "age_desc              4-11 years\n",
      "relation                  Parent\n",
      "Class/ASD                    YES\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the same dataset used by the app\n",
    "df_full = pd.read_csv(\"Autism-Child-Data.csv\")\n",
    "\n",
    "# Find a row where the Class/ASD is \"YES\"\n",
    "positive_rows = df_full[df_full[\"Class/ASD\"] == \"YES\"]\n",
    "\n",
    "if not positive_rows.empty:\n",
    "    # Take the first known positive row\n",
    "    known_positive = positive_rows.iloc[0]\n",
    "    print(\"Known positive row found:\\n\", known_positive)\n",
    "else:\n",
    "    print(\"No rows with 'YES' found in the dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358852a0-e0a0-42aa-83f0-b4d00f650ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
