{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ef9f7e-bec6-465b-b44c-70aca9693370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (1.43.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (2.2.1)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (4.11.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.7)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kiit\\anaconda3\\envs\\my_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit scikit-learn seaborn joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2cb793-f824-451a-bb5b-ebbfb2734a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: Index(['id', 'A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score',\n",
      "       'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age',\n",
      "       'gender', 'ethnicity', 'jundice', 'austim', 'contry_of_res',\n",
      "       'used_app_before', 'result', 'age_desc', 'relation', 'Class/ASD'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Autism-Child-Data.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print column names\n",
    "print(\"Columns in dataset:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3affae4d-a821-4118-b87e-026f10d99c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically detect the last column as target\n",
    "target_column = df.columns[-1]\n",
    "\n",
    "# Convert categorical target values into numerical values (0 or 1)\n",
    "df[target_column] = df[target_column].map({'YES': 1, 'NO': 0})  # Adjust mapping as needed\n",
    "\n",
    "# Handle missing values in the target column by assignment instead of inplace\n",
    "df[target_column] = df[target_column].fillna(0)\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f22c742-930d-4586-9d1b-0a82b4f91088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# Set Your OpenAI API Key (for local dev/testing)\n",
    "# ---------------------------\n",
    "openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# ---------------------------\n",
    "# Updated CSS to match header's pastel gradient\n",
    "# ---------------------------\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    @import url('https://fonts.googleapis.com/css2?family=Nunito:wght@400;600&display=swap');\n",
    "\n",
    "    /* Global pastel gradient background (pink to orange/yellow) */\n",
    "    html, body, .stApp {\n",
    "        height: 100% !important;\n",
    "        margin: 0 !important;\n",
    "        padding: 0 !important;\n",
    "        /* Replace these colors if you want a slightly different pastel blend */\n",
    "        background: linear-gradient(135deg, #FFC1CC, #FFD3FF, #FFFACD) !important;\n",
    "        background-size: cover !important;\n",
    "        background-repeat: no-repeat !important;\n",
    "        color: #333 !important;\n",
    "        font-family: 'Nunito', sans-serif !important;\n",
    "    }\n",
    "\n",
    "    /* Main content container: semi-transparent white so gradient shows behind */\n",
    "    .main .block-container {\n",
    "        background: rgba(255, 255, 255, 0.7) !important;\n",
    "        border: 1px solid #ddd !important;\n",
    "        border-radius: 8px !important;\n",
    "        box-shadow: 0 2px 5px rgba(0,0,0,0.05) !important;\n",
    "        padding: 2rem !important;\n",
    "        margin: 2rem auto !important;\n",
    "    }\n",
    "\n",
    "    /* Sidebar with a reversed pastel gradient for harmony */\n",
    "    .sidebar .sidebar-content {\n",
    "        background: linear-gradient(135deg, #FFFACD, #FFD3FF, #FFC1CC) !important;\n",
    "        border-right: 1px solid #ddd !important;\n",
    "        padding-top: 2rem !important;\n",
    "        padding-left: 1rem !important;\n",
    "        padding-right: 1rem !important;\n",
    "        color: #333 !important;\n",
    "    }\n",
    "\n",
    "    .sidebar h2 {\n",
    "        font-size: 1.3rem !important;\n",
    "        font-weight: 600 !important;\n",
    "        margin-bottom: 1rem;\n",
    "        color: #111 !important;\n",
    "    }\n",
    "\n",
    "    /* Headings in a darker shade for contrast */\n",
    "    h1, h2, h3, h4, h5, h6 {\n",
    "        font-family: 'Nunito', sans-serif !important;\n",
    "        color: #111 !important;\n",
    "        margin-top: 0.5rem;\n",
    "        margin-bottom: 0.5rem;\n",
    "    }\n",
    "\n",
    "    /* Buttons with pastel gradient to match header */\n",
    "    .stButton>button {\n",
    "        background: linear-gradient(135deg, #FFC1CC, #FFD3FF, #FFFACD) !important;\n",
    "        color: #333 !important;\n",
    "        border: 1px solid #ccc;\n",
    "        border-radius: 5px;\n",
    "        font-weight: 600;\n",
    "        font-size: 1rem;\n",
    "        padding: 0.6rem 1rem;\n",
    "        cursor: pointer;\n",
    "    }\n",
    "    .stButton>button:hover {\n",
    "        background: linear-gradient(135deg, #FFFACD, #FFD3FF, #FFC1CC) !important;\n",
    "        color: #111 !important;\n",
    "    }\n",
    "\n",
    "    .stTextInput>div>div>input, .stSelectbox>div>div>div>input, .stNumberInput input {\n",
    "        background-color: #FFFFFF !important;\n",
    "        color: #333 !important;\n",
    "        border-radius: 5px;\n",
    "        border: 1px solid #ccc !important;\n",
    "    }\n",
    "\n",
    "    .dataframe {\n",
    "        border: 1px solid #ccc !important;\n",
    "        border-radius: 5px;\n",
    "        margin-bottom: 1rem;\n",
    "    }\n",
    "\n",
    "    .mpl-figure, .mpl-figure-zoom, .mpl-figure-tooltip {\n",
    "        background-color: rgba(255, 255, 255, 0.7) !important;\n",
    "    }\n",
    "\n",
    "    /* Bordered-text class for interactive boxes */\n",
    "    .bordered-text {\n",
    "        border: 1px solid #ccc;\n",
    "        border-radius: 6px;\n",
    "        padding: 1rem;\n",
    "        background-color: rgba(255, 255, 255, 0.8);\n",
    "        margin-bottom: 1rem;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Helper Functions\n",
    "# ---------------------------\n",
    "def preprocess_data(df, target_column):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset:\n",
    "      - Convert all string columns to lowercase (and strip whitespace) to unify categories\n",
    "      - Drop columns that may leak information.\n",
    "      - Convert the target column from 'YES'/'NO' to 1/0 if needed.\n",
    "      - Label encode non-numeric columns (except target).\n",
    "    \"\"\"\n",
    "    # 1) Unify text columns\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].str.strip().str.lower()\n",
    "    \n",
    "    # 2) Drop columns that may leak information\n",
    "    for col in ['Age_Mons', 'id', 'result']:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    # 3) Convert target column from YES/NO to 1/0 if needed\n",
    "    if df[target_column].dtype == 'object':\n",
    "        df[target_column] = df[target_column].map({'yes': 1, 'no': 0})\n",
    "        df[target_column] = df[target_column].fillna(0)\n",
    "    \n",
    "    # 4) Label encode the remaining categorical columns\n",
    "    label_encoders = {}\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and col != target_column:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    return df, label_encoders\n",
    "\n",
    "def generate_gpt_response(user_input):\n",
    "    \"\"\"\n",
    "    Generates a response using OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert on Autism Spectrum Disorder. Provide helpful, accurate information.\"},\n",
    "                {\"role\": \"user\", \"content\": user_input},\n",
    "            ],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# ---------------------------\n",
    "# Streamlit App Navigation\n",
    "# ---------------------------\n",
    "pages = [\"Welcome\", \"Instructions\", \"Sample Dataset\", \"Prediction\", \"AI Chatbot\"]\n",
    "page = st.sidebar.radio(\"Navigation\", pages)\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Welcome Page\n",
    "# ---------------------------\n",
    "if page == \"Welcome\":\n",
    "    st.image(\"ASD_Header.png\", use_container_width=True)\n",
    "\n",
    "    st.title(\"Welcome to the ASD Detection Web App\")\n",
    "    st.markdown(\"\"\"\n",
    "    <div class=\"bordered-text\">\n",
    "    <strong>What is ASD?</strong><br><br>\n",
    "    Autism Spectrum Disorder (ASD) is a developmental condition that impacts how individuals communicate, behave, and interact with the world around them. \n",
    "    It is called a \"spectrum\" because symptoms and severity can vary widely from person to person.<br><br>\n",
    "\n",
    "    <strong>ASD in Children:</strong><br><br>\n",
    "    Children with ASD often show signs like difficulty in social interactions, repetitive behaviors, and sensitivity to sensory inputs. \n",
    "    Early intervention can greatly improve outcomes by providing support with communication, social skills, and learning strategies.<br><br>\n",
    "\n",
    "    <strong>ASD in Adults:</strong><br><br>\n",
    "    Many adults with ASD lead fulfilling lives, but they may continue to experience challenges in social relationships, \n",
    "    employment, and daily functioning. Proper support, accommodations, and understanding can help them thrive.<br><br>\n",
    "\n",
    "    <strong>How This Web App Helps:</strong><br><br>\n",
    "    This web application assists in the <em>early detection</em> of ASD, particularly for children, by using data analysis and machine learning. \n",
    "    It allows you to upload a dataset, train or load a pre-trained model, and then make predictions about whether a child might show signs of ASD. \n",
    "    Additionally, it features an AI-powered chatbot that can answer questions about ASD, its symptoms, and possible interventions.\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Instructions Page\n",
    "# ---------------------------\n",
    "elif page == \"Instructions\":\n",
    "    st.title(\"Instructions\")\n",
    "    st.markdown(\"\"\"\n",
    "    <div class=\"bordered-text\">\n",
    "    <strong>How to Use this Web App:</strong><br><br>\n",
    "    1. <strong>Sample Dataset:</strong><br>\n",
    "       Go to the 'Sample Dataset' page to preview and download a sample dataset on child autism.<br><br>\n",
    "    2. <strong>Prediction:</strong><br>\n",
    "       On the 'Prediction' page, upload your dataset (CSV format) or use the sample data. \n",
    "       The app will preprocess the data, load or train a RandomForest model, evaluate its performance, and allow you to make predictions.<br><br>\n",
    "    3. <strong>AI Chatbot:</strong><br>\n",
    "       The 'AI Chatbot' page features an AI-powered chatbot where you can ask any questions related to ASD and receive informative responses.<br><br>\n",
    "    <em>Note:</em> This tool is for educational purposes only and should not replace professional medical advice.\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Sample Dataset Page\n",
    "# ---------------------------\n",
    "elif page == \"Sample Dataset\":\n",
    "    st.title(\"Sample Child Autism Dataset\")\n",
    "    st.markdown(\"Download this sample dataset to test the ASD Detection System.\")\n",
    "\n",
    "    try:\n",
    "        # Make sure 'Autism-Child-Data.csv' is in the same folder as this script\n",
    "        df_sample = pd.read_csv(\"Autism-Child-Data.csv\")\n",
    "        st.write(df_sample.head())\n",
    "\n",
    "        # Convert the DataFrame to CSV for download\n",
    "        csv_data = df_sample.to_csv(index=False)\n",
    "        st.download_button(\n",
    "            label=\"Download Child Autism CSV\",\n",
    "            data=csv_data,\n",
    "            file_name=\"Autism-Child-Data.csv\",\n",
    "            mime=\"text/csv\"\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Autism-Child-Data.csv not found. Please place it in the same directory as this app.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Prediction Page\n",
    "# ---------------------------\n",
    "elif page == \"Prediction\":\n",
    "    st.title(\"ASD Prediction for Children\")\n",
    "    uploaded_file = st.file_uploader(\"Upload your Autism-Child-Data.csv file\", type=[\"csv\"])\n",
    "    \n",
    "    if uploaded_file:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        st.subheader(\"Dataset Preview\")\n",
    "        st.write(df.head())\n",
    "        \n",
    "        target_column = \"Class/ASD\"\n",
    "        st.write(f\"Detected Target Column: **{target_column}**\")\n",
    "        \n",
    "        # Preprocess data and prepare for model training\n",
    "        df_processed, encoders = preprocess_data(df.copy(), target_column)\n",
    "        X = df_processed.drop(columns=[target_column])\n",
    "        y = df_processed[target_column].astype(int)\n",
    "        \n",
    "        model_file = \"asd_model_children.pkl\"\n",
    "        retrain_flag = False\n",
    "        try:\n",
    "            model = joblib.load(model_file)\n",
    "            # Check for leaking columns in the pre-trained model\n",
    "            if hasattr(model, \"feature_names_in_\") and any(leak in model.feature_names_in_ for leak in [\"id\", \"result\"]):\n",
    "                st.warning(\"Pre-trained model contains leaking columns. Retraining to remove them.\")\n",
    "                retrain_flag = True\n",
    "        except FileNotFoundError:\n",
    "            retrain_flag = True\n",
    "        \n",
    "        if retrain_flag:\n",
    "            st.write(\"ðŸ›  Training new model without leaking columns...\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "            model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "            joblib.dump(model, model_file)\n",
    "            st.write(\"âœ… Model trained and saved.\")\n",
    "        else:\n",
    "            st.write(\"âœ… Pre-trained model loaded.\")\n",
    "        \n",
    "        # ---------------------------\n",
    "        # Model Evaluation (Bar Chart + Heatmap)\n",
    "        # ---------------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        st.subheader(f\"Model Accuracy on Test Split: {accuracy:.2%}\")\n",
    "\n",
    "        # Cross-Validation Scores (Bar Chart)\n",
    "        cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "        st.markdown(\"**Cross-Validation Scores:**\")\n",
    "        fig_cv, ax_cv = plt.subplots()\n",
    "        ax_cv.bar(range(len(cv_scores)), cv_scores, color='#bbb')\n",
    "        ax_cv.set_xlabel(\"Fold\")\n",
    "        ax_cv.set_ylabel(\"CV Score\")\n",
    "        ax_cv.set_ylim([0, 1])\n",
    "        ax_cv.set_title(\"Cross-Validation Scores\")\n",
    "        st.pyplot(fig_cv)\n",
    "\n",
    "        mean_cv = cv_scores.mean()\n",
    "        st.markdown(f\"**Mean CV Accuracy:** {mean_cv:.2%}\")\n",
    "\n",
    "        # Confusion Matrix (Heatmap)\n",
    "        preds = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "        st.markdown(\"**Confusion Matrix (Heatmap):**\")\n",
    "        fig_cm, ax_cm = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm)\n",
    "        ax_cm.set_xlabel(\"Predicted\")\n",
    "        ax_cm.set_ylabel(\"Actual\")\n",
    "        st.pyplot(fig_cm)\n",
    "\n",
    "        # Classification Report (Styled DataFrame)\n",
    "        st.markdown(\"**Classification Report:**\")\n",
    "        report_dict = classification_report(y_test, preds, output_dict=True)\n",
    "        df_report = pd.DataFrame(report_dict).transpose()\n",
    "        st.dataframe(df_report.style.background_gradient(cmap='Blues', axis=1))\n",
    "\n",
    "        # ---------------------------\n",
    "        # Prediction Inputs\n",
    "        # ---------------------------\n",
    "        st.subheader(\"Make a Prediction\")\n",
    "        user_input = {}\n",
    "        for col in X.columns:\n",
    "            if col in encoders:\n",
    "                original_categories = list(encoders[col].classes_)\n",
    "                user_input[col] = st.selectbox(f\"Select {col}\", original_categories)\n",
    "            else:\n",
    "                min_val = float(X[col].min())\n",
    "                max_val = float(X[col].max())\n",
    "                median_val = float(X[col].median())\n",
    "                user_input[col] = st.number_input(f\"Enter value for {col}\", min_val, max_val, median_val)\n",
    "        \n",
    "        if st.button(\"Predict\"):\n",
    "            st.write(\"Current user inputs:\", user_input)\n",
    "            input_df = pd.DataFrame([user_input])\n",
    "            for col, le in encoders.items():\n",
    "                if col in input_df.columns:\n",
    "                    user_value = input_df[col].iloc[0]\n",
    "                    valid_classes = set(le.classes_)\n",
    "                    if user_value not in valid_classes:\n",
    "                        st.error(f\"Unseen category '{user_value}' for column '{col}'. Please pick a valid option.\")\n",
    "                        st.stop()\n",
    "                    else:\n",
    "                        input_df[col] = le.transform(input_df[col])\n",
    "            prediction = model.predict(input_df)[0]\n",
    "            result_text = \"ASD Positive\" if prediction == 1 else \"ASD Negative\"\n",
    "            st.success(f\"Prediction: **{result_text}**\")\n",
    "\n",
    "        # ---------------------------\n",
    "        # Data Analysis (Count Plot + Optional Correlation Heatmap)\n",
    "        # ---------------------------\n",
    "        st.subheader(\"Data Analysis\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.countplot(x=df[target_column], ax=ax)\n",
    "        ax.set_title(\"Distribution of ASD Classification\")\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        st.markdown(\"**Correlation Heatmap:**\")\n",
    "        corr = df_processed.corr()\n",
    "        fig_corr, ax_corr = plt.subplots(figsize=(10, 6))\n",
    "        sns.heatmap(corr, ax=ax_corr, cmap=\"coolwarm\", annot=False)\n",
    "        ax_corr.set_title(\"Correlation Heatmap of Processed Features\")\n",
    "        st.pyplot(fig_corr)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) AI Chatbot Page\n",
    "# ---------------------------\n",
    "elif page == \"AI Chatbot\":\n",
    "    st.title(\"AI-Powered Chatbot\")\n",
    "    st.markdown(\"Ask any questions related to Autism Spectrum Disorder (ASD) and get responses powered by AI.\")\n",
    "\n",
    "    user_query = st.text_input(\"Your Question:\")\n",
    "    if st.button(\"Send\"):\n",
    "        if user_query:\n",
    "            with st.spinner(\"Generating response...\"):\n",
    "                response = generate_gpt_response(user_query)\n",
    "            st.markdown(\"**Chatbot:**\")\n",
    "            st.write(response)\n",
    "        else:\n",
    "            st.error(\"Please enter a question.\")\n",
    "    \n",
    "    st.markdown(\"**Disclaimer:** This chatbot is for informational purposes only and should not replace professional medical advice.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312c5fcb-7e8e-4d35-b0ae-cd7a9e14740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2429eca-cf7a-46b3-8cbe-704aad44d83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f99dc64-6954-4edf-9602-603ead646200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae21430-176e-41ef-9013-dad800fc3d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.anaconda', '.bito', '.cache', '.conda', '.condarc', '.continuum', '.ipynb_checkpoints', '.ipython', '.jupyter', '.matplotlib', '.mozilla', '.ms-ad', '.nbi', '.oracle_jre_usage', '.profile', '.redhat', '.vivado_hls', '.vscode', '.Xilinx', '1styrresult.pdf', 'ai', 'AICTE Internship profile.pdf', 'anaconda3', 'app.py', 'AppData', 'Application Data', 'archive (3).zip', 'archive (4).zip', 'archive.zip', 'ASD_Project.ipynb', 'Autism-Child-Data.csv', 'Automobile.csv', 'c-prog', 'clg', 'Cloud_Fundamental.pptx[1].pdf', 'Contacts', 'Cookies', 'Documents', 'Downloads', 'Favorites', 'ibm', 'IMG_20241221_192029.jpg', 'IMG_5454.jpeg.jpg', 'IMG_5471.png', 'IMG_5578.jpeg.jpg', 'inAsc.txt', 'inDesc.txt', 'indian_summer_beauty_products.csv', 'inRand.txt', 'IntelGraphicsProfiles', 'Introduction_to_Cloud.pptx[1].pdf', 'KIIT HDFC Payment gateway.pdf', 'LAB1_3629.ipynb', 'LAB2_3629.ipynb', 'LAB3Dictinaryy.ipynb', 'LAB3Dictionary_3629.ipynb', 'LAB5.ipynb', 'LINEAR_REG.ipynb', 'Links', 'Local Settings', 'Matplotlib.ipynb', 'MATPLOTLIB.py', 'matplotlib_LAB5.ipynb', 'MinGW Installer.lnk', 'ML', 'movies.csv', 'Music', 'My Documents', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{2ad838bb-efea-11ee-a54d-000d3a94eaa1}.TxR.0.regtrans-ms', 'NTUSER.DAT{2ad838bb-efea-11ee-a54d-000d3a94eaa1}.TxR.1.regtrans-ms', 'NTUSER.DAT{2ad838bb-efea-11ee-a54d-000d3a94eaa1}.TxR.2.regtrans-ms', 'NTUSER.DAT{2ad838bb-efea-11ee-a54d-000d3a94eaa1}.TxR.blf', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TM.blf', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'Numpy.ipynb', 'OneDrive', 'Oracle', 'outMergeAsce.txt', 'outMergeDesc.txt', 'outMergeRand.txt', 'output.csv', 'PANDAS.ipynb', 'PrintHood', 'Projection of Solid.dwg', 'QEM_intro.pdf', 'Recent', 'Registration for Forma.ai Internship Cum PPO Recruitment Drive - 2026 Graduating Batch.pdf', 'Registration for JP Morgan Chase (SEP) â€“ Full Time for 2026 Graduating Batch.pdf', 'Remittance Form KIIT FEST 8.0 TIMELESS KANVAS.docx', 'Salaries.csv', 'Saved Games', 'Searches', 'second.c', 'sem1', 'SendTo', 'shrey.am', 'Start Menu', 'student_data.csv', 'Templates', 'TIMELESS KANVAS_RF.docx', 'uhv', 'UNIT_-_1a.pptx[1].pdf', 'UNIT_-_1b.pptx[1].pdf', 'Untitled.ipynb', 'Untitled1.ipynb', 'Videos', 'Virtualization.pptx[1].pdf', 'VM_Provisioning.pptx[1].pdf', 'WPS Cloud Files']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2ef32a5-ffeb-4a35-90ea-f8342bac34b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known positive row found:\n",
      " id                             5\n",
      "A1_Score                       1\n",
      "A2_Score                       1\n",
      "A3_Score                       1\n",
      "A4_Score                       1\n",
      "A5_Score                       1\n",
      "A6_Score                       1\n",
      "A7_Score                       1\n",
      "A8_Score                       1\n",
      "A9_Score                       1\n",
      "A10_Score                      1\n",
      "age                            5\n",
      "gender                         m\n",
      "ethnicity                 Others\n",
      "jundice                      yes\n",
      "austim                        no\n",
      "contry_of_res      United States\n",
      "used_app_before               no\n",
      "result                        10\n",
      "age_desc              4-11 years\n",
      "relation                  Parent\n",
      "Class/ASD                    YES\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the same dataset used by the app\n",
    "df_full = pd.read_csv(\"Autism-Child-Data.csv\")\n",
    "\n",
    "# Find a row where the Class/ASD is \"YES\"\n",
    "positive_rows = df_full[df_full[\"Class/ASD\"] == \"YES\"]\n",
    "\n",
    "if not positive_rows.empty:\n",
    "    # Take the first known positive row\n",
    "    known_positive = positive_rows.iloc[0]\n",
    "    print(\"Known positive row found:\\n\", known_positive)\n",
    "else:\n",
    "    print(\"No rows with 'YES' found in the dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358852a0-e0a0-42aa-83f0-b4d00f650ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
